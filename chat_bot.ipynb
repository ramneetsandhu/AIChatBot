{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-zUa5sNDSir5"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttJsfaJpUnzU",
        "outputId": "510400bb-add5-4780-b4ae-8ef131a3c329"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "wI7UEszsUt_k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries needed for tensorflow processing\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import json"
      ],
      "metadata": {
        "id": "JiqkSAVRU5q8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "kf6RS0xkVGaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import our chat - bot intents file\n",
        "with open('intents.json') as json_data:\n",
        "  intents = json.load(json_data)"
      ],
      "metadata": {
        "id": "z2qazo7ZVbG7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore = ['?']\n",
        "\n",
        "# loop through each sentence in the intent's pattern\n",
        "for intent in intents['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    # tokenize each and every word in the sentence\n",
        "    w = nltk.word_tokenize(pattern)\n",
        "    # add word to the words list\n",
        "    words.extend(w)\n",
        "    # add words(s) to documents\n",
        "    documents.append((w, intent['tag']))\n",
        "    # add tags to our classes list\n",
        "    if intent['tag'] not in classes:\n",
        "      classes.append(intent['tag'])"
      ],
      "metadata": {
        "id": "R-vyFwy9Xw4L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform stemming and lower each word as well as remove duplicates\n",
        "words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
        "words = sorted(list(set(words)))"
      ],
      "metadata": {
        "id": "w7HdR_2brEIv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove duplicate classes\n",
        "classes = sorted(list(set(classes)))"
      ],
      "metadata": {
        "id": "0o4zwcrmrGvK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training data\n",
        "training = [] # X -- data\n",
        "output = [] # Y -- label\n",
        "\n",
        "# create an empty array for output\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "# create training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "  # initialize bag of words\n",
        "  bag = []\n",
        "  # list of tokenized words for the pattern\n",
        "  pattern_words = doc[0]\n",
        "  # stemming each word\n",
        "  pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
        "  # create bag of words array\n",
        "  for w in words:\n",
        "    bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "  # output is '1' for current tag and '0' for rest of other tags\n",
        "  output_row = list(output_empty)\n",
        "  output_row[classes.index(doc[1])] = 1\n",
        "\n",
        "  training.append([bag, output_row])\n",
        "\n",
        "# shffling feature and turning it into np.array\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "# creating training lists\n",
        "train_x = list(training[:, 0])\n",
        "train_y = list(training[:, 1])"
      ],
      "metadata": {
        "id": "WICHtqTptNQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aba73fa-3019-4189-acb7-7303f151d459"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-e0d1558a1b5a>:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  training = np.array(training)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10, input_shape=(len(train_x[0]),))) # we are taking 10 neuron in first param\n",
        "model.add(tf.keras.layers.Dense(10)) #\n",
        "model.add(tf.keras.layers.Dense(len(train_y[0]), activation='softmax')) # More than two classes is multi-classification . For Multi-classification we have to use softmax\n",
        "model.compile(tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wtELN8g6TdQP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(np.array(train_x), np.array(train_y), epochs=100, batch_size=8, verbose=1) # fit use for train the model\n",
        "model.save(\"model.pkl\")"
      ],
      "metadata": {
        "id": "Yk3Tz9TSaKpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34bb625e-cc44-4113-b923-967184e26b75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 4ms/step - loss: 3.7314 - accuracy: 0.0909\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.6918 - accuracy: 0.1405\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3.6555 - accuracy: 0.1653\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3.6178 - accuracy: 0.1818\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3.5789 - accuracy: 0.1983\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.5341 - accuracy: 0.2149\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3.4879 - accuracy: 0.2397\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3.4336 - accuracy: 0.2645\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.3746 - accuracy: 0.2645\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.3097 - accuracy: 0.2810\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.2403 - accuracy: 0.2810\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.1696 - accuracy: 0.2893\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.0946 - accuracy: 0.3058\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.0165 - accuracy: 0.3388\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.9355 - accuracy: 0.3471\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.8558 - accuracy: 0.3471\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.7695 - accuracy: 0.3636\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.6854 - accuracy: 0.3884\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.6022 - accuracy: 0.4132\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.5173 - accuracy: 0.4380\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.4347 - accuracy: 0.4545\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.3533 - accuracy: 0.4876\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.2683 - accuracy: 0.5124\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.1881 - accuracy: 0.5124\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.1075 - accuracy: 0.5207\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.0303 - accuracy: 0.5289\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.9553 - accuracy: 0.5289\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.8799 - accuracy: 0.5455\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.8087 - accuracy: 0.5868\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.7374 - accuracy: 0.6198\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.6679 - accuracy: 0.6116\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.6022 - accuracy: 0.6446\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.5382 - accuracy: 0.6777\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.4743 - accuracy: 0.6942\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.4142 - accuracy: 0.7273\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3548 - accuracy: 0.7438\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.2979 - accuracy: 0.7438\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.2408 - accuracy: 0.7686\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1833 - accuracy: 0.7934\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1323 - accuracy: 0.8099\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0794 - accuracy: 0.8264\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0286 - accuracy: 0.8595\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9827 - accuracy: 0.8512\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9373 - accuracy: 0.8760\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8923 - accuracy: 0.9008\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8509 - accuracy: 0.9008\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.8926\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7746 - accuracy: 0.8926\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.9008\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.9008\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.9091\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.9091\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.9091\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.9256\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.9256\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.9256\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.9256\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.9256\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.9256\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.9256\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.9174\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.9339\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.9339\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.9421\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.9421\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.9504\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.9504\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.9587\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.9587\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2909 - accuracy: 0.9669\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.9669\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.9669\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.9669\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.9669\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 0.9669\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.9669\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9669\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2186 - accuracy: 0.9669\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9669\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2045 - accuracy: 0.9669\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9669\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9669\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9669\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1800 - accuracy: 0.9669\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9669\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9669\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9669\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1603 - accuracy: 0.9669\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9669\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9669\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9669\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9669\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9669\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9669\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9669\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 0.9669\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9669\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9669\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9669\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump( {'words': words, 'classes': classes}, open(\"training_data\", \"wb\"))\n"
      ],
      "metadata": {
        "id": "Rnp8XWoBy1Q7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"model.pkl\")"
      ],
      "metadata": {
        "id": "SWAl0ldqzJv1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restoring all the data structures\n",
        "data = pickle.load(open(\"training_data\", \"rb\"))\n",
        "words = data['words']\n",
        "classes = data['classes']"
      ],
      "metadata": {
        "id": "tqZNBjHjuEQW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"intents.json\") as json_data:\n",
        "  intents = json.load(json_data)"
      ],
      "metadata": {
        "id": "hgPBO3JDuWQE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_up_sentence(sentence):\n",
        "  # tokenizing the pattern\n",
        "  sentence_words = nltk.word_tokenize(sentence)\n",
        "  # stemming each word\n",
        "  sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
        "  return sentence_words\n",
        "\n",
        "# returning bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "def bow(sentence, words):\n",
        "  # tokenizing the pattern\n",
        "  sentence_words = clean_up_sentence(sentence)\n",
        "  # generating bag of words\n",
        "  bag = [0]*len(words)\n",
        "  for s in sentence_words:\n",
        "    for i, w in enumerate(words):\n",
        "      if w == s:\n",
        "        bag[i] = 1\n",
        "  bag=np.array(bag)\n",
        "  return (bag)\n"
      ],
      "metadata": {
        "id": "IIAfDcH3uqgO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ERROR_THRESHOLD = 0.30\n",
        "\n",
        "def classify(sentence):\n",
        "  # generate probabilities from the model\n",
        "  bag = bow(sentence, words)\n",
        "  results = model.predict(np.array([bag]))\n",
        "  # filter out predictions below a threshold\n",
        "  results = [[i,r] for i,r in enumerate(results[0]) if r > ERROR_THRESHOLD]\n",
        "  # sort by strength of probability\n",
        "  results.sort(key=lambda x:x[1], reverse=True)\n",
        "  return_list = []\n",
        "  for r in results:\n",
        "    return_list.append((classes[r[0]], r[1]))\n",
        "  # return tuple of intent and probablity\n",
        "  return return_list"
      ],
      "metadata": {
        "id": "MsKpHF9CxU1K"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(sentence):\n",
        "  results = classify(sentence)\n",
        "  # if we have a classification then find the matching intent tag\n",
        "  if results:\n",
        "    # loop as long as there are matches to process\n",
        "    count = 0\n",
        "    while results:\n",
        "      for i in intents['intents']:\n",
        "        # find a tag matcing the first result\n",
        "        if i['tag'] == results[0][0]:\n",
        "          # a random response from the intent\n",
        "          return print(random.choice(i['responses']))\n",
        "        results.pop(0)"
      ],
      "metadata": {
        "id": "vqtms4fBzU2g"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response('Hi how are you')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg5DoFXv00vW",
        "outputId": "260d6622-06a7-4b37-d25a-03ab55a9e865"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "Hello, thanks for asking\n"
          ]
        }
      ]
    }
  ]
}